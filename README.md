# Scalar implicatures: how are they perceived by LM's?
### This work addresses the problem of scalar implicatures acquisition in language models and answers several research questions:
- Can models learn and generate pragmatic inferences?
- Do LLM results differ in the classification of different types of implicatures?
- How similar is the “perception” of scalar implicatures by models to human perception?
- What methods can be used to train models for scalar implicatures?

For classification we used topological methods, such as:
- Extraction of Persistent Homology Dimension
- Mapping
